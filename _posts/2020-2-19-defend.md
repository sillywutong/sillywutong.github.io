---
title: "[论文阅读笔记]假新闻检测 dEFEND: Explainable Fake News Detection" 
category: Paper Reading
tags: [news, attention]
excerpt_separator: <!--more-->
---

论文： dEFEND: Explainable Fake News Detection

KDD2019：

[KDD 2019 | dEFEND: Explainable Fake News Detection](https://www.kdd.org/kdd2019/accepted-papers/view/defend-explainable-fake-news-detection)

# ABSTRACT

本文研究的问题是假新闻检测，假新闻检测可以看作一个分类问题，它和谣言分类、fact check、垃圾内容挖掘等比较相似，都属于内容质量检测的领域。假新闻检测的研究方向主要有三个：

1. 数据集： 假新闻标准数据集需要人工去构建。
2. 特征方面的工作： 假新闻检测的方法可以分为基于内容和基于社交网络，这些方法都涉及到新闻文本的embedding、用户的embedding、用户之间社交网络的embedding如何获取的问题。
3. 模型研究。

本文提出，虽然之前的工作在假新闻检测上获得了比较准确的结果，但是这些模型都不是可解释的，不能告诉我们为什么判定这篇新闻是假新闻。他们提出了一个融合模型，根据新闻内容和用户评论来检测，同时能够筛选出Top-k 用户评论来解释为什么这条新闻是假的。作者在真实数据集上做实验，结果比7个模型f1-score高出5.33%，精确度大幅提升。

<!--more-->
# Introduction

这一部分主要讲了为什么假新闻检测很重要，现在新闻的传播有什么样的特点， 假新闻检测的困难在哪里，作者做出了什么样的贡献。

首先随着社交网络的用户大幅增长，人们获取新闻的渠道改变，2018年已经有68%的美国成年人从社交网络上获取新闻。但社交媒体上的创作形式和传播速度让用户每天接触到大量的错误信息和虚假信息，广泛传播的假新闻会损害公众对政府、媒体的信任，改变人们对真新闻的看法，还可能对现实世界造成伤害。

假新闻检测的困难在于：

1. 因为假新闻本来就是故意写来误导读者的，它在内容上可能逻辑自洽，语气客观，仅仅基于内容很难判定它的真伪。
2. 不能只基于内容，要结合用户评论（或者有一些模型也研究了传播特性（网络结构），以及多条新闻下多个评论用户之间的社交关系、用户的特征等）， 但社交网络数据非常庞大，有很多用户是匿名的，有很多机器人账号，这导致评论和转发中有较多的噪声。近年来比较优秀的一篇是natali他们提出来的，他们综合了新闻内容，用户评论，回复的用户的特征和关系网络来检测假新闻。也有用attention机制的，在大量的用户回复中筛选出那些重要的回复。

作者从另一个角度提出研究课题，即在检测的同时还要解释为什么它是假新闻。这么做的好处首先是对特征研究有贡献；然后这么做有利于从噪声中分离对判断真假有用的信息，从而提高判断的准确度。

什么叫做解释为什么？ 作者是从两个角度去解决的，解释可以从新闻内容中得到，也可以从用户评论中得到。

1. 新闻内容中有一些信息是可以验证真伪的，例如涉及科学知识、人文历史等等，记者可以到一些第三方的事实鉴定网站去鉴定，但对于新的事件知识库里还没有信息，就没法检查。
2. 用户评论含有大量信息，如立场、情感、观点，可以帮助检测
3. 新闻内容和用户评论会有联动，用户评论可能针对新闻中某句话/某个观点提出质疑，也可以解释一条新闻为什么被判定真假。

从这两个角度去挖掘原因，作者提出的框架包括3个部分：

1. 编码新闻内容的模块， 具体是采用一个层级注意力网络。
2. 编码用户评论的模块，用的是word-level注意力子网络。
3. sentence-comment co-attention component，用来捕捉新闻内容和用户评论之间的关系，以及选出能够解释检测结果的top-k条用户评论和新闻句子。

这篇文章强调了以下的挑战：

1. 如何同时提高检测准确度和可解释性
2. 如何提取解释性的句子和评论，在没有真值的情况下
3. 如何对新闻内容和用户评论之间的关系建模。

总结他们的贡献，有三个方面。一是他们提出了基于社交网络的假新闻检测领域的新问题，即如何解释检测结果；二是针对这个问题提出了一个模型，三是在真实数据集上测量模型的准确性和可解释性。

# Related work

关于假新闻检测：

[一文看懂虚假新闻检测（附数据集 & 论文推荐）](https://zhuanlan.zhihu.com/p/57124028)

新闻检测分为基于新闻内容的和基于社交环境的。基于新闻内容的模型可以从文本和视觉元素提取特征。文本特征可以包括写作风格、情感等，来判断新闻写作是否中立客观；视觉特征从配图、视频中提取。

基于社交环境的方法，可以包括用户、推文、社交网络三个方面的特征，用户特征是指从用户的资料来描述用户，推文是指根据用户以往的评论、推文来检测他们的立场、可信度。网络特征指的是对该新闻的传播模式、用户之间的互动关系等进行建模。

## 可解释的机器学习

机器学习模型的可解释性也是研究的热点。可以分为两种： intrinsic 和post-hoc explainability。前者是把可解释性融合进模型结构本身，例如用权重的大小来寻找重要特征；后者是创建另外一个模型来对一个已有的模型进行解释，比如说用一个决策树，训练到能和一个神经网络产生一样的结果。

这篇paper用层级注意力机制就是intrinsic的方法。

# 问题定义

A 是一篇文章， 有N个句子si

每个句子有Mi个单词，记为 w1，……wMi

C={ c1……cT} 是T条评论，每条评论有w1……wQj 个单词。

新闻检测问题看作是二分类问题，要学习的是分类，以及该新闻所有的T条评论的一个排序，和该新闻所有N个句子的一个排序。排序的一句是解释能力。新闻句子的解释能力指的是这个句子的信息有多check-worthy（我理解的check-worthy指的是检查有多容易以及这个句子信息的真假对

# 模型

1. 新闻内容编码
2. 用户评论编码
3. sentence-comment co-attention
4. prediction

## News contents encoding

使用的是word-sentence level的注意力机制。最近的研究喜欢用层级注意力网络来表示文本，就像上一篇新闻推荐的论文，这种网络可以根据目标的不同更好地选择特征。

1. word encoder： encoder用的是双向GRU RNN。每一个单词用相应正向和反向两个单元的隐状态共同表示，包含了这个单词的上下文信息（而不是只有上文）。在这之上就是一个常规的attention 网络，权重α描述了每一个单词对该句子表示的贡献。一个句子向量vi就是单词表示的加权和。

    $$  \begin{aligned}
&\overrightarrow{\mathrm{h}_{t}^{\vec{\prime}}}=\overrightarrow{G R U}\left(\mathbf{w}_{t}^{i}\right), t \in\left\{1, \ldots, M_{i}\right\}\\
&\overleftarrow{\mathrm{h}_{t}^{i}}=\overleftarrow{G R U}\left(\mathrm{w}_{t}^{i}\right), t \in\left\{M_{i}, \ldots, 1\right\}
\end{aligned}  $$

   $$  \mathbf{v}^{i}=\sum_{t=1}^{M_{i}} \alpha_{t}^{i} \mathbf{h}_{t}^{i}  $$

2. sentence encoder： 也是用双向 GRU RNN。将该新闻的N个句子向量作为输入，每个句子的表示si用正向和反向的隐状态连接。

    $$ \overrightarrow{\mathrm{h}^{i}}=\overrightarrow{G R U}\left(\mathrm{v}^{i}\right), i \in\{1, \ldots, N\}$$
$$\overleftarrow{\mathrm{h}^{i}}=\overleftarrow{G R U}\left(\mathrm{v}^{i}\right), i \in\{N, \ldots, 1\} $$

## User Comments Encoding

因为评论比较短所以就直接用word attention了。这个embedding首先是直接将每个词映射到一个embedding 矩阵的一个向量，embedding的维度是D维。然后将评论的所有单词embedding输入一个双向GRU RNN, 然后还是用相似的方法， 把隐状态加权和得到comment vector cj。

## Sentence-Comment Co-attention

- affinity matrix： also called similarity matrix。矩阵来衡量x和y轴数据点的相似度，常用的有余弦距离。
- attention map： 是一维的attention 机制的扩展。二维的attention map是一个数值矩阵，每一个数值衡量该坐标数据点对特点目标的重要程度：attention map: a scalar matrix representing the relative importance of layer activations at different 2D spatial locations with respect to the target task。
- 首先构建相似度矩阵：
    $$ \mathrm{F}=\tanh \left(\mathrm{C}^{\mathrm{T}} \mathrm{W}_{l} \mathrm{S}\right) $$
- 用相似度矩阵来进一步构建二维attention 网络的权重。
    $$ \begin{aligned}
&\mathrm{H}^{s}=\tanh \left(\mathrm{W}_{s} \mathrm{S}+\left(\mathrm{W}_{c} \mathrm{C}\right) \mathrm{F}\right)\\
&\mathrm{H}^{c}=\tanh \left(\mathrm{W}_{c} \mathrm{C}+\left(\mathrm{W}_{s} \mathrm{S}\right) \mathrm{F}^{\mathrm{T}}\right)
\end{aligned} $$
    $$ \begin{array}{l}
{\mathbf{a}^{S}=\operatorname{softmax}\left(\mathbf{w}_{h s}^{\top} \mathbf{H}^{s}\right)} \\
{\mathbf{a}^{c}=\operatorname{softmax}\left(\mathbf{w}_{h c}^{\top} \mathbf{H}^{c}\right)}
\end{array} $$

    其中，as是所有N个句子的权重， ac是所有T条评论的权重。最后，句子加权和和评论加权和分别作为最终该新闻句子的表示和评论的表示。

    $$ \hat{\mathbf{s}}=\sum_{i=1}^{N} \mathbf{a}_{i}^{s} \mathbf{s}^{i}, \quad \hat{\mathbf{c}}=\sum_{j=1}^{T} \mathbf{a}_{j}^{c} \mathbf{c}^{j} $$

    没看懂这个模块的数学含义，comment和sentence在事实上的相似度如何影响attention权重的？F矩阵中有w参数需要训练，但这个训练过程怎么能让F真的就代表comment和sentence之间的相似度呢？还有看起来F越接近0应该是相似度越低的，这样Hs直接=tanh（WsS）而与C无关。我们的目标函数真的能让F的参数往这个方向去优化吗？

## Prediction

- 预测函数：

    $$ \hat{\mathbf{y}}=\operatorname{softmax}\left([\hat{\mathbf{s}}, \hat{\mathbf{c}}] \mathbf{W}_{f}+\mathbf{b}_{f}\right) $$

    这里y head是个二维向量，表示y预测为0或1的概率。

- 目标函数：

    $$ \mathcal{L}(\theta)=-y \log \left(\hat{y}_{1}\right)-(1-y) \log \left(1-\hat{y}_{0}\right) $$

模型使用RMSprop作为优化器。

# 实验

实验探究3个问题：

1. defend模型能否提高假新闻检测的表现？
2. 能提高分类表现，那么新闻内容和用户评论，分别对提高的贡献有多大？
3. defend能找到可以解释分类结果的句子和用户评论吗？

## 数据集

[PolitiFact](https://www.politifact.com/)

用了一个新闻检测benchmark: FakeNewsNew. 里面的数据是从两个fact-checking平台 GossipCop和PoilitiFact获取的，PolitiFact是一个非营利性的事实鉴定平台，由用户上传statement，由调查记者调查并给出statement鉴定和调查报告。鉴定不是简单的真或者假，而是分了好几个级别。作者过滤了不足3条评论的新闻。

## 比较方法

对比了以往七种方法，其中前两种对新闻内容的语言学特征提取和建模，还利用了心理学的知识（没具体看），HAN用层级注意力网络，但是只基于新闻内容；text-CNN用CNN去编码新闻内容。

TCNN-URG用卷积网络学习新闻内容特征和用户评论特征。HPA不是基于新闻内容，反而从评论用户去获取该新闻的表示，也用了层级注意力网络。CSI则是混合方法，基于新闻内容、用户评论文本、用户特征来检测，是2017年提出之后很受关注的方法。

这个实验针对问题选取了三种不同的比较组，选取的逻辑非常清晰。

## DEFEND分类表现

- 用常规accuracy precision recall 和 f1来衡量。
- RST\LIWC\HAN： 这三个都是只基于新闻内容的传统方法，HAN各项评分都高很多，说明层级注意力网络编码特征的能力最强； LIWC优于RST，说明语言特征对假新闻检测很有帮助。
- 融合用户评论的方法比单纯使用新闻内容或单纯使用评论的方法性能好。说明用户评论的确包含了新闻真伪的补充信息。
- 只用用户信息的方法比只用新闻内容的方法稍微好一些。

## 量化模型中user comment/新闻内容对检测的影响

有几个defend变种：

- dEDEND\C： 去掉用户评论，编码新闻内容之后，直接pooling和softmax
- defend、N： 不考虑新闻内容。
- defend\Co: 不用co-attention，而是在新闻内容和用户评论上分别做sentence级别的self-attention。

结果：

![results](/assets/images/paper/defend.png)

作者的结论是： co=attention、新闻内容、用户评论都会有贡献。然而，他们没有提到 新闻内容和用户评论在两个数据集上的作用很不一样，且po上F1比Accuracy高，Gossip上相反，这是为什么。他们也没有对这两个数据集做基本的介绍。

## 解释性和case study

对比的方法是HAN 和 HPA。

1. sentence： 使用工具ClaimBuster，这个工具是一个对claim的check-worthy程度进行打分的模型，是用竞选辩论数据集去训练的，label是人们手工标注的。和HAN对比，使用MAP（mean average precisionk）。 （这里对准确对应的ground-truth，应该是把新闻输入claim buster去标注的）。 结果是defend好于HAN，好于Random
2. comments： comments解释性的评价就更厉害了……他们选了50篇文章（去掉不足50个词的，超过500个单词就截短），然后雇佣了AMT众包工人来评估每篇文章选出来的评论TOPK LIST。第一个任务是在DEFEND 和 HPA 得到的两个rank list（用attention 权重从大到小排列选出来的）之间进行ABtest。这个任务用三个角度来评估： 
1. rc1和rc2投票人数比
2. rc1和rc2获胜的新闻条数比。
3. 每条新闻，保证会被3个worker投票，每条新闻的比分

结果是rc1票数远比rc2多，在新闻比分上，3：0和2：1加起来大于60%。

第二个任务，是让工人对list里面的每一条评论进行0-4解释性打分。评价标准是NDCG和Precision，这里Precision指的是在rank list里面的条目是相关条目的比例。

## Case Study

里面确实highlight了非常有价值的用户评论，且和文本有很强对应；有用的评论也比无关信息、有太强主观性的评论得分高。

# Future work

- 结合fact-checking 网站上列出来的调查结论，可能可以更好地highlight新闻句子和用户评论
- 结合更多的用户信息，例如评论获得点赞数，也可能更好帮助筛选重要评论
        